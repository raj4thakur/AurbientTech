{% load static %}
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>AI Interview ‚Äî Aurbient</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    .btn-primary { background: linear-gradient(90deg,#6C47FF,#9A5CFF); color:#fff; padding:10px 14px; border-radius:999px; font-weight:600; }
    .card { background: linear-gradient(180deg,#fff,#fbf8ff); border-radius:12px; box-shadow:0 6px 20px rgba(20,18,53,0.06); padding:16px; }
  </style>
</head>
<body class="bg-gray-50 font-sans">
  <div class="max-w-4xl mx-auto p-6">
    <h1 class="text-3xl font-bold mb-3">AI Interview (Voice-enabled)</h1>
    <p class="text-sm muted mb-4">Pick a track, click Start, speak your answers or type them. The assistant will score and provide feedback.</p>

    <div class="card mb-4">
      <div class="flex gap-3 items-center">
        <select id="track" class="p-2 border rounded">
          <option value="hr">HR Interview</option>
          <option value="tech">Technical Interview</option>
        </select>
        <input id="name" placeholder="Name (optional)" class="p-2 border rounded flex-1" />
        <input id="email" placeholder="Email (optional)" class="p-2 border rounded w-64" />
        <button id="startBtn" class="btn-primary">Start Interview</button>
      </div>
      <div class="mt-3 text-xs muted">Microphone access will be requested for voice capture. Works best in Chrome/Edge.</div>
    </div>

    <div id="interviewCard" class="card hidden">
      <div class="mb-3 flex items-center justify-between">
        <div>
          <strong id="currentQuestion">Question will appear here</strong>
          <div id="progressText" class="text-sm muted">Answered: <span id="answeredCount">0</span></div>
        </div>
        <div class="flex gap-2">
          <button id="recStart" class="px-3 py-2 border rounded">üé§ Start Voice</button>
          <button id="recStop" class="px-3 py-2 border rounded">‚èπ Stop</button>
        </div>
      </div>

      <textarea id="typedAnswer" rows="4" class="w-full border rounded p-2 mb-3" placeholder="Or type your answer here..."></textarea>
      <div class="flex gap-2">
        <button id="submitAnswer" class="btn-primary">Submit Answer</button>
        <button id="nextQ" class="px-3 py-2 border rounded">Next Question</button>
      </div>

      <div id="transcriptBlock" class="mt-3 text-sm muted"></div>
    </div>

    <div id="resultCard" class="card hidden mt-4">
      <h3 class="text-xl font-semibold">Interview Evaluation</h3>
      <div id="resultArea" class="mt-3"></div>
      <a id="pdfLink" class="btn-primary inline-block mt-4" href="#">Download PDF</a>
    </div>
  </div>

<script>
let recognition = null;
let isRecording = false;
let transcriptText = "";
let currentQuestion = "";
let answered = 0;
const csrftoken = (() => {
  const name='csrftoken'; const cookies=document.cookie.split(';').map(s=>s.trim());
  for(const c of cookies) if(c.startsWith(name+'=')) return decodeURIComponent(c.split('=')[1]); return '';
})();

async function startSession(){
  const payload = { track: document.getElementById('track').value, name: document.getElementById('name').value, email: document.getElementById('email').value };
  const resp = await fetch("{% url 'ai_interview:api_start' %}", {
    method:'POST', headers: {'Content-Type':'application/json','X-CSRFToken': csrftoken}, body: JSON.stringify(payload)
  });
  const data = await resp.json();
  currentQuestion = data.next_question;
  document.getElementById('currentQuestion').textContent = currentQuestion;
  document.getElementById('interviewCard').classList.remove('hidden');
}

async function fetchNextQuestion(){
  const resp = await fetch("{% url 'ai_interview:api_question' %}", { method:'POST', headers:{'X-CSRFToken': csrftoken} });
  const data = await resp.json();
  currentQuestion = data.next_question;
  return currentQuestion;
}

async function submitAnswer(answer){
  const payload = { question: currentQuestion, answer: answer, transcript: transcriptText };
  const resp = await fetch("{% url 'ai_interview:api_submit_answer' %}", {
    method:'POST', headers: {'Content-Type':'application/json','X-CSRFToken': csrftoken}, body: JSON.stringify(payload)
  });
  const data = await resp.json();
  return data;
}

// wiring UI
document.getElementById('startBtn').addEventListener('click', async ()=>{
  await startSession();
  document.getElementById('startBtn').disabled = true;
});

document.getElementById('recStart').addEventListener('click', ()=>{
  if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) { alert('Speech API not supported in this browser.'); return; }
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  recognition = new SR();
  recognition.lang = 'en-US';
  recognition.interimResults = true;
  recognition.continuous = true;
  recognition.onresult = (event)=>{
    let interim = '';
    for(let i=event.resultIndex;i<event.results.length;i++){
      const r = event.results[i];
      if(r.isFinal) transcriptText += r[0].transcript + '\\n';
      else interim += r[0].transcript;
    }
    document.getElementById('transcriptBlock').textContent = transcriptText + interim;
  };
  recognition.onerror = (e)=> console.error('Speech error', e);
  recognition.start();
  isRecording = true;
});

document.getElementById('recStop').addEventListener('click', ()=>{
  if (recognition && isRecording) { recognition.stop(); isRecording = false; }
});

document.getElementById('submitAnswer').addEventListener('click', async ()=>{
  const typed = document.getElementById('typedAnswer').value.trim();
  const answerText = typed || transcriptText;
  if (!answerText) { alert('Please speak or type your answer.'); return; }
  const res = await submitAnswer(answerText);
  // update UI
  answered += 1;
  document.getElementById('answeredCount').textContent = answered;
  document.getElementById('typedAnswer').value = '';
  transcriptText = '';
  document.getElementById('transcriptBlock').textContent = '';
  // ask model whether to continue
  const next = await fetch("{% url 'ai_interview:api_question' %}", { method:'POST', headers: {'X-CSRFToken': csrftoken} });
  const nextData = await next.json();
  if (nextData.next_question){
    currentQuestion = nextData.next_question;
    document.getElementById('currentQuestion').textContent = currentQuestion;
  } else {
    // finalize (we use the finalize endpoint in server side helper api_question_and_finalize if you prefer; we call it here)
    const finalize = await fetch("{% url 'ai_interview:api_question_and_finalize' %}", { method:'POST', headers: {'X-CSRFToken': csrftoken} });
    const fin = await finalize.json();
    if (fin.result){
      document.getElementById('resultCard').classList.remove('hidden');
      const area = document.getElementById('resultArea');
      area.innerHTML = `<pre style="white-space:pre-wrap">${JSON.stringify(fin.result, null, 2)}</pre>`;
      if (fin._db_id) {
        document.getElementById('pdfLink').href = "{% url 'ai_interview:result_pdf' 0 %}".replace('/0/','/' + fin._db_id + '/');
      } else {
        document.getElementById('pdfLink').style.display = 'none';
      }
      document.getElementById('interviewCard').classList.add('hidden');
    } else {
      alert('Interview complete but we could not produce a result. Try again later.');
    }
  }
});

document.getElementById('nextQ').addEventListener('click', async ()=>{
  const nextData = await fetch("{% url 'ai_interview:api_question' %}", { method:'POST', headers: {'X-CSRFToken': csrftoken} });
  const nd = await nextData.json();
  if (nd.next_question) {
    currentQuestion = nd.next_question;
    document.getElementById('currentQuestion').textContent = currentQuestion;
  } else {
    alert('No further questions ‚Äî submit your last answer to finalize.');
  }
});
</script>
</body>
</html>
